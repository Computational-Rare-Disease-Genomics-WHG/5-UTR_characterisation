2. 5’UTR Composition Analysis
================

Using MANE v1, here we gather various other 5’UTR features and
information

1.  PhyloP scores 1.1 PhyloP scores for 5UTR 1.2 uORF starts PhyloP 1.3
    uORF stops PhyloP 1.4 Start-stops PhyloP
2.  CADD scores
3.  RNAfold  
4.  CAGE peak  
5.  Ribo-seq uORFs
6.  Translational Efficiency (Noderer Et al 2014)

\#load libraries

``` r
library(gridExtra)
library(grid)
library(ape)
library(stringr)
library(ggplot2)
library(stats)
library(splitstackshape)
library(dplyr)
library(GenomicScores)
library(seqinr)
```

\#1. PhyloP scores

``` r
#PhyloP is a per-base measurement of conservation between species
#Author: Alex Geary

#######################1. 5UTR mean PhyloP score#########################

#1. get data ready
df1<-read.gff(".../MANE.GRCh38.v1.0.ensembl_genomic.gff", na.strings = c(".", "?"), GFF3 = TRUE)[c(1,3:5,9)]

#Calculate mean 5' and 3' length
fives<-subset(df1, type=="five_prime_UTR")
mean_fives<-(((sum(fives$end)) - (sum(fives$start)))/(nrow(fives)))

##2. Obtain and analyse PhyloP scores##
#do this if not working and needs updates
#install.packages("BiocManager")
#BiocManager::install("GenomicScores")
library(GenomicScores)
#yavailableGScores() #Available data
phast <- getGScores("phyloP100way.UCSC.hg38")

#3. Obtain and average scores for each UTR in the 5' and 3' data (Positive scores — Measure conservation, Negative scores — Measure acceleration.)
fives$PGS<-"NA" #Introduce new column with NA values
for(i in 1:(nrow(fives))){ #for all elements of dataset
  gs1<-gscores(phast, GRanges(seqnames=(as.character(fives$seqid[i])), IRanges(start=(as.numeric(fives$start[i])):(as.numeric(fives$end[i])), width=1))) #Obtain a set of scores from within UTR coordinates
  gs1<-na.omit(gs1) #do not count missing data (avoid skewing)
  scores1<-gs1@elementMetadata@listData[["default"]] #Extract scores from GRanges object
  pgs1<-(sum(scores1)/length(scores1)) #Divide the sum of scores by number of scores in the calculation
  fives$PGS[i]<-list(pgs1) #add to the output data the mean
}
fives$PGS<-as.numeric(fives$PGS)

#ran in terminal as takes a while
fives <- read.table("/Users/nwieder/phylop/fives.txt")
#note#
#Positive scores — Measure conservation, which is slower evolution than expected, at sites that are predicted to be conserved.
#Negative scores — Measure acceleration, which is faster evolution than expected, at sites that are predicted to be fast-evolving

#split attributes out
five_split <- cSplit(fives, "attributes", ";")
#remove titles
names(five_split)[8]<-"gene_id"
names(five_split)[9]<-"transcript_id"
names(five_split)[11]<-"gene"
names(five_split)[14]<-"exon_number"
names(five_split)[16]<-"mane_type"

titles <- c("gene_id","transcript_id","gene","exon_number","mane_type")

five_split[,titles]<- lapply(five_split[,titles,with=FALSE], function(x) gsub("\\w+=", "", x))

#want mane select only
five_split_mane <- five_split[grepl("MANE_Selec", five_split$mane_type), ]

#now need to get PGS scores for whole UTR. now they are per 5'UTR exon 
phylop_final <- five_split_mane[, .(agg_PGS=sum(PGS)/.N), by=transcript_id]

phylop_final2 <- merge(phylop_final, length_exon, by = "transcript_id")

##note, PGS == phylop score
#save 
write.table(phylop_final2, ".../five_utr_ph_m1_10.1.23.txt")

#######################2. uORF Starts Phylop########################
#phylop is per base so get for the ATG and mean of the 3 bases
#Author: Nechama Wieder

#install.packages("BiocManager")
#BiocManager::install("GenomicScores")

#yavailableGScores() #Available data
phast <- getGScores("phyloP100way.UCSC.hg38")


#bring in the df of predicted uORFs with positions

uorf_gen <- read.delim(file=".../ORFs_genomic_coord_12.12.22.txt") 

###########uorf starts#################
#do + and - strands seperately 
uorf_pos <- uorf_gen %>% filter(strand_mane=="+")
uorf_pos$aug_end <- uorf_pos$g_start_coord_ref+2

uorf_pos$phylop <-"NA"
for(i in 1:(nrow(uorf_pos))){
  gs1 <- gscores(phast, GRanges(seqnames=(as.character(uorf_pos$chromosome[i])), IRanges(start=(as.numeric(uorf_pos$g_start_coord_ref[i])):(as.numeric(uorf_pos$aug_end[i])), width=1)))
  gs1<-na.omit(gs1)
  scores1<-gs1@elementMetadata@listData[["default"]]#granges isnt dataframe so need to extract it like this
  phylop <- (sum(scores1)/length(scores1))  #Divide the sum of scores by number of scores in the calculation
  uorf_pos$phylop[i]<- list(phylop)
  uorf_pos$one_two_three<- length(scores1)
}
#this takes a while to run

#get rid of phylop col bec its complaining
uaug_ph <- as.numeric(uorf_pos$phylop)
uorf_pos$phylop2 <- uaug_ph
uaug_phylop <- subset(uorf_pos, select=-c(phylop))

#save so dont need to re run as takes a long time
#write.table(uaug_phylop,"uorf start pos phylop 31.7.22.txt")


#run on negative strands

uorf_neg <- uorf_gen %>% filter(strand_mane == "-")
uorf_neg$aug_start<- uorf_neg$g_end_coord_ref-2
uorf_neg$aug_end <- uorf_neg$g_end_coord_ref

uorf_neg$phylop <-"NA"
for(q in 1:(nrow(uorf_neg))){
  gs1 <- gscores(phast, GRanges(seqnames=(as.character(uorf_neg$chromosome[q])), IRanges(start=(as.numeric(uorf_neg$aug_start[q])):(as.numeric(uorf_neg$aug_end[q])), width=1)))
  gs1<-na.omit(gs1)
  scores1<-gs1@elementMetadata@listData[["default"]]#granges isnt dataframe so need to extract it like this
  phylop <- (sum(scores1)/length(scores1))  #Divide the sum of scores by number of scores in the calculation
  uorf_neg$phylop[q]<- list(phylop)
  uorf_neg$one_two_three<- length(scores1)
}

#save
uaug_neg <- as.numeric(uorf_neg$phylop)
uorf_neg$phylop2 <- uaug_neg
uaug_neg2 <- subset(uorf_neg, select=-c(phylop))

#write.table(uaug_neg2,".../uorf start neg phylop m1 8.1.23.txt")



#bind  pos and neg together to get one df with all uorf starts phylop
#the uorf gneomic coords can contain introns so bit of fiddling to get the exact bits

###1. phylop for uorf starts
starts_pos <- read.table(".../uorf start pos phylop m1 8.1.23.txt")
starts_pos <- starts_pos %>% filter(strand_mane=="+")

#now these are uorfs that are split by introns, so i only want the ones which start with ATG
#pull sequences 
library("BSgenome.Hsapiens.UCSC.hg38")
human <- getBSgenome("BSgenome.Hsapiens.UCSC.hg38")
#add chr to begining
starts_pos$chromosome <- paste0("chr", starts_pos$chromosome)
starts_pos$start <- as.character(Biostrings::getSeq(BSgenome.Hsapiens.UCSC.hg38, starts_pos$chromosome, starts_pos$g_start_coord_ref, starts_pos$aug_end))
table(starts_pos$start)
#remove non atg starts - this is from my predicted set. non atg starts are not wanted
starts_pos2 <- starts_pos%>% filter(start=="ATG")

#now do neg
starts_neg <- read.table(".../uorf start neg phylop m1 8.1.23.txt")
starts_neg$chromosome <- paste0("chr", starts_neg$chromosome)
#test run to see which end i want
#i think its the end minus 2
#tester <- as.character(Biostrings::getSeq(BSgenome.Hsapiens.UCSC.hg38, chr4, 11428756, 11428758)) #CAT
#this is right. i can chuck out anything not CAT

starts_neg$start <- as.character(Biostrings::getSeq(BSgenome.Hsapiens.UCSC.hg38, starts_neg$chromosome, starts_neg$g_end_coord_ref-2, starts_neg$g_end_coord_ref))
table(starts_neg$start)

starts_neg2 <- starts_neg %>% filter(start=="CAT")

#check the 1 2 3 of each
table(starts_neg2$one_two_three)
table(starts_pos2$one_two_three)
#all threes 

#bind them together and now i have all uorf start phylop scores
neg2 <- subset(starts_neg2, select=-c(aug_start))
uorf_st_phy <- rbind(neg2, starts_pos2) #yas

#save 
#write.table(uorf_st_phy, "uorf starts phylop 9.1.23.txt")




################3. uORF stops phylop################
#subset
uorf_pos_st <- subset(uorf_pos, select=-c(aug_end,phylop, phylop2, one_two_three))
uorf_neg_st <- subset(uaug_neg2, select=-c(aug_start,aug_end,phylop2, one_two_three))

#positive strand uorf stops phylop

uorf_pos_st$uorf_end <- uorf_pos_st$g_end_coord_ref -2
#pull one example to make sure its pulling correct sequence
#test <- as.character(Biostrings::getSeq(BSgenome.Hsapiens.UCSC.hg38, "chr11", 64305601, 64305603)) - its correct


uorf_pos_st$phylop <-"NA"
for(r in 1:(nrow(uorf_pos_st))){
  gs1 <- gscores(phast, GRanges(seqnames=(as.character(uorf_pos_st$chromosome[r])), IRanges(start=(as.numeric(uorf_pos_st$uorf_end[r])):(as.numeric(uorf_pos_st$g_end_coord_ref[r])), width=1)))
  gs1<-na.omit(gs1)
  scores1<-gs1@elementMetadata@listData[["default"]]#granges isnt dataframe so need to extract it like this
  phylop <- (sum(scores1)/length(scores1))  #Divide the sum of scores by number of scores in the calculation
  uorf_pos_st$phylop[r]<- list(phylop)
  uorf_pos_st$one_two_three<- length(scores1)
}

#save
uorfst <- as.numeric(uorf_pos_st$phylop)
uorf_pos_st$phylop2 <- uorfst
uorf_pos_st2 <- subset(uorf_pos_st, select=-c(phylop))
#write.table(uorf_pos_st2,"uorf end pos phylop 9.1.23.txt")


#negative strand uorf ends phylop
uorf_neg <- uorf_gen %>% filter(strand_mane=="-")
uorf_neg_st <- uorf_neg
#start +2
#test <- as.character(Biostrings::getSeq(BSgenome.Hsapiens.UCSC.hg38, "chr17", 47820345, 47820347)) #TCA - AGT - TGA when rev comp. this is correct

uorf_neg_st$uorf_end <- uorf_neg_st$g_start_coord_ref+2

uorf_neg_st$phylop <-"NA"
for(t in 1:(nrow(uorf_neg_st))){
  gs1 <- gscores(phast, GRanges(seqnames=(as.character(uorf_neg_st$chromosome[t])), IRanges(start=(as.numeric(uorf_neg_st$g_start_coord_ref[t])):(as.numeric(uorf_neg_st$uorf_end[t])), width=1)))
  gs1<-na.omit(gs1)
  scores1<-gs1@elementMetadata@listData[["default"]]#granges isnt dataframe so need to extract it like this
  phylop <- (sum(scores1)/length(scores1))  #Divide the sum of scores by number of scores in the calculation
  uorf_neg_st$phylop[t]<- list(phylop)
  uorf_neg_st$one_two_three<- length(scores1)
}

#save
uorfst2 <- as.numeric(uorf_neg_st$phylop)
uorf_neg_st$phylop2 <- uorfst2 
uorf_neg_st2 <- subset(uorf_neg_st, select=-c(phylop))
#write.table(uorf_neg_st2,"uorf end neg phylop m1 9.1.23.txt")


####PHYLOP FOR UORF stops -bind pos and neg together, and clean data
##POS
end_pos <- read.table(".../uorf end pos phylop 9.1.23.txt")
#using uorf position coords, pull the ends of uORFs and check that its stop codons - needs to be TAA/TAG/TGA. if it isnt, exclude

end_pos$chromosome <- paste0("chr", end_pos$chromosome)
end_pos$stop <- as.character(Biostrings::getSeq(BSgenome.Hsapiens.UCSC.hg38, end_pos$chromosome, end_pos$g_end_coord_ref-2, end_pos$g_end_coord_ref))
table(end_pos$stop)
#remove non stop codon
end_pos2 <- end_pos%>% filter(stop %in% c("TAA", "TAG", "TGA"))
#check
#table(end_pos2$stop)


###NEG
end_neg <- read.table(".../uorf end neg phylop m1 9.1.23.txt")

end_neg$chromosome <- paste0("chr", end_neg$chromosome)
#start plus 2
end_neg$stop <- as.character(Biostrings::getSeq(BSgenome.Hsapiens.UCSC.hg38, end_neg$chromosome, end_neg$g_start_coord_ref, end_neg$g_start_coord_ref+2))

table(end_neg$stop)
#remove non stop codon
end_neg2 <- end_neg%>% filter(stop %in% c("TTA", "TCA", "CTA"))
uorf_end_phy <- rbind(end_neg2, end_pos2) #yas
#save
#write.table(uorf_end_phy, "uorf ends phylop m1 10.1.23.txt")

################### 4. start-stops phylop #####################
# mean for whole start stop
#these coords will run across introns

#make one df with phylop for starts and ends, then split into uORFs and ss's
start_pos <- read.table(".../uorf start pos phylop m1 8.1.23.txt")
names(start_pos)[10]<-"ph_start"

start_neg <- read.table(".../uorf start neg phylop m1 8.1.23.txt")
names(start_neg)[11]<-"ph_start"

end_pos<-read.table(".../uorf end pos phylop 9.1.23.txt")
names(end_pos)[10]<-"ph_end"
end_neg <-read.table(".../uorf end neg phylop m1 9.1.23.txt")
names(end_neg)[10]<-"ph_end"

#split into uorf and ss
start_pos$group <- "uORF Start"
start_neg$group<-"uORF Start"
#get them all into 1 df
start_neg <- subset(start_neg, select=-c(aug_start))
phylop_st <- rbind(start_neg, start_pos)
names(phylop_st)[10]<-"phylop"
#split into uorf and ss
uorf_start <- phylop_st %>% filter(u_id2=="uORF")
ss_start <- phylop_st %>% filter(u_id2=="start-stop")
ss_start$group <- "Start-Stop Start"

end_pos$group <-"uORF end"
end_neg$group <- "uORF end"
phylop_end <- rbind(end_neg, end_pos)
ph_end <- phylop_end$ph_end
phylop_end$ph_end <- ph_end
names(phylop_end)[10]<-"phylop"

#split into ss and uorf
names(phylop_end)[8]<-"aug_end"
uorf_end <- phylop_end %>% filter(u_id2=="uORF")
ss_end <- phylop_end %>% filter(u_id2=="start-stop")
ss_end$group <- "Start-Stop End"

#bind all the df together so i get uorf start, uorf end, ss start and ss end

phylop <- rbind(uorf_start, uorf_end, ss_start, ss_end)

#save
#write.table(phylop,".../uorf_ss phylop m1 10.1.23.txt")

#get mean ss phylop (for start and end) as one phylop score
#make a new df with mean ss phylop and do again
names(ss_start)[10] <- "phylop_st"
names(ss_end)[10] <- "phylop_end"
ss_start$phylop_end <- ss_end$phylop_end
ss_start$phylop <- (ss_start$phylop_st + ss_start$phylop_end) /2 
ss <- subset(ss_start, select=-c(phylop_st, phylop_end))
ss$group <- "Start-Stop"

phylop2 <- rbind(uorf_start, uorf_end, ss)
#write.table(phylop2,".../uorf_ss phylop m1 10.1.23.txt")
```

\#2. CADD scores

``` r
#scores of variant deleteriousness for all possible variants at each position

##1. Prepare files to be run on cluster

#want 2 files: 1  with chr start and end, 1 with strand and exon
mane_five <- read.table(".../mane_five.txt")

five <- subset(mane_five, select=c(V1, V4, V5))
#rename
names(five)[1] <- "chr"
names(five)[2] <- "start"
names(five)[3] <- "end"

#save as TSV
#write_tsv(five, ".../MANE v1_five.tsv")


#make another one with some more info
five_more <- data.frame(mane_five$V1, mane_five$V4, mane_five$V5, mane_five$V7, mane_five$transcript_id, mane_five$exon_number)
names(five_more)[1] <- "chr"
names(five_more)[2] <- "start"
names(five_more)[3] <- "end"
names(five_more)[4] <- "strand"
names(five_more)[5] <- "transcript_id"
names(five_more)[6] <- "exon_number"

#save as tsv
#write_tsv(five_more, ".../MANE v1_five_more.tsv")


####run on cluster####
#Author:Elston  Neil    D'Souza
#bash
#!/bin/sh

# The following script subsets tabix on the
# BMRC using the bed file using tabix

# module load BCFtools
CADD_INPATH='/well/whiffin/projects/cadd'
CADD_OUTPUT='/well/whiffin/users/wdf915/Projects/5prime_UTR'

tabix ${CADD_INPATH}/whole_genome_SNVs.tsv.gz \
            --regions ${CADD_OUTPUT}/five.tsv \
            > ${CADD_OUTPUT}/output.txt

####


#2. Bring data back into R and sort
cadd <- read.delim(".../CADD m1.txt", header=FALSE)

#for each position,  i want the average CADD score
#rename
cadd <- setNames(cadd, c("chr","pos","ref", "alt", "cadd", "phred"))

cadd2 <- cadd %>% group_by(chr, pos) %>% summarise(cadd_mean=mean(cadd))
#write.table(cadd2, ".../cadd_scores_m1.txt")
#this is a score for each position within the 5'UTR, so I need to compute for the sections i want

###CADD for 5'UTR (mean)
#need to calculate each exon mean CADD
#then aggregate by transcript id

#prepare exon file, this is five from above "MANE v1_five.tsv"

#quicker to run this in terminal and this code as an R script
#takes about 2 hours
#exon file needs to be the five_more data above
five_more$chr <- str_replace(five_more$chr, "chr", "") 
#save: write.table(five_more, ".../exon_m1.txt")
exon <- read.table(".../exon_m1.txt")
cadd <- read.table(".../cadd_scores_m1.txt")

for(r in 1:nrow(exon)){
  c <- exon$chr[r]
  s <- exon$start[r]
  e <- exon$end[r]
  small_cadd <- subset(cadd, chr==c)
  small_cadd <- subset(small_cadd, pos >= s) 
  small_cadd <- subset(small_cadd, pos <= e)
  cadd_score <- as.vector(small_cadd$cadd_mean)
  exon$cadd[r] <- mean(cadd_score)
}

write.table(exon, ".../fiveutr_cadd_m1.txt")
#R < .../cadd_5UTRs_m1.R --save



###CADD for uORF start and ends
#make this an R script and run in terminal
#R < .../uorf_st_end_cadd.R --save
#bring in uorf genomic coords file

cadd <- read.table(".../cadd_scores_m1.txt")
uorf_gen <- read.table(".../ORFs_genomic_coord_12.12.22.txt")

#need the positions for the start/end of uORF and need to do the strands seperately

uorf_pos <- uorf_gen%>%filter(strand_mane=="+")
uorf_pos$aug_end <- uorf_pos$g_start_coord_ref+2
uorf_pos$stop_end <- uorf_pos$g_end_coord_ref+2

###1. uorf pos starts###
for(i in 1:nrow(uorf_pos)){
  c <- uorf_pos$chromosome[i]
  s <- uorf_pos$g_start_coord_ref[i]
  e <- uorf_pos$aug_end[i]
  small_cadd <- subset(cadd2, chr==c)
  small_cadd <- subset(small_cadd, pos >= s) 
  small_cadd <- subset(small_cadd, pos <= e)
  cadd_score <- as.vector(small_cadd$cadd_mean)
  uorf_pos$cadd[i] <- mean(cadd_score)
}

uorf_cadd_starts <- uorf_pos
write.table(uorf_cadd_starts, ".../uorf_pos_starts_m1.txt")

###2. uorf neg starts###
uorf_neg <- uorf_gen%>%filter(strand_mane=="-")
uorf_neg$aug_start<- uorf_neg$g_end_coord_ref-2
uorf_neg$aug_end <- uorf_neg$g_end_coord_ref

for(q in 1:nrow(uorf_neg)){
  c <- uorf_neg$chromosome[q]
  s <- uorf_neg$aug_start[q]
  e <- uorf_neg$aug_end[q]
  small_cadd <- subset(cadd, chr==c)
  small_cadd <- subset(small_cadd, pos >= s) 
  small_cadd <- subset(small_cadd, pos <= e)
  cadd_score <- as.vector(small_cadd$cadd_mean)
  uorf_neg$cadd_start[q] <- mean(cadd_score)
}
neg_starts <- uorf_neg

write.table(neg_starts, ".../uorf_neg_starts_m1.txt")


###3. uorf pos ends#####
for(f in 1:nrow(uorf_pos)){
  c <- uorf_pos$chromosome[f]
  s <- uorf_pos$g_end_coord_ref[f]
  e <- uorf_pos$stop_end[f]
  small_cadd <- subset(cadd, chr==c)
  small_cadd <- subset(small_cadd, pos >= s) 
  small_cadd <- subset(small_cadd, pos <= e)
  cadd_score <- as.vector(small_cadd$cadd_mean)
  uorf_pos$cadd2[f] <- mean(cadd_score)
}
uorf_cadd_ends <- uorf_pos

write.table(uorf_cadd_ends, ".../uorf_pos_ends_m1.txt")



###4.uorf neg ends####
uorf_neg$stop <- uorf_neg$g_start_coord_ref
uorf_neg$stop_end <- uorf_neg$g_start_coord_ref+2

for(w in 1:nrow(uorf_neg)){
  c <- uorf_neg$chromosome[w]
  s <- uorf_neg$stop[w]
  e <- uorf_neg$stop_end[w]
  small_cadd <- subset(cadd, chr==c)
  small_cadd <- subset(small_cadd, pos >= s) 
  small_cadd <- subset(small_cadd, pos <= e)
  cadd_score <- as.vector(small_cadd$cadd_mean)
  uorf_neg$cadd_stop[w] <- mean(cadd_score)
}

neg_end <- uorf_neg
write.table(neg_end, ".../uorf_neg_ends_m1.txt")


#######bring all the 4 df for uorf start and ends back into R and make into 1 useable df#####
#bring all data in once run in terminal

start_pos <- read.table(".../uorf_pos_starts_m1.txt")
start_neg <- read.table(".../uorf_neg_starts_m1.txt")
end_pos <- read.table(".../uorf_pos_ends_m1.txt")
end_neg <- read.table(".../uorf_neg_ends_m1.txt")


start_pos$group <- "uORF Start"
start_neg$group <- "uORF Start"
end_pos$group <- "uORF Stop"
end_neg$group <- "uORF Stop"

#make 1 df with all pos uorfs
uorf_pst <- subset(start_pos, select = c(t_id, u_id2 , cadd, group))
uorf_pend <- subset(end_pos, select = c(t_id, u_id2 , cadd, group))

uorf_p <- rbind(uorf_pst, uorf_pend)
#remove start stops
uorf_p <- uorf_p[uorf_p$u_id2 !="start-stop", ]
##this is correct, and have start and stops in it

#1 df for all neg uorfs
uorf_n_st <- subset(start_neg, select = c(t_id, u_id2 , cadd_start, group))
uorf_n_end <- subset(end_neg, select = c(t_id, u_id2 , cadd_stop, group))
names(uorf_n_st)[3] <- "cadd"
names(uorf_n_end)[3] <- "cadd"
uorf_n <- rbind(uorf_n_end,uorf_n_st)
uorf_n <- uorf_n[uorf_n$u_id2 !="start-stop", ]

#bind pos and neg uorfs
uorf_cadd <- rbind(uorf_p, uorf_n)


#### start stops
#i want one df of start stops with both cadds in and i can get  a mean of the 2
#add the cadd scores for uorf ends to uorf start df
start_pos$cadd_stop <- end_pos$cadd
names(start_pos)[10]<-"cadd_start"
start_pos$cadd <- (start_pos$cadd_start + start_pos$cadd_stop)/2
ss_p <- start_pos %>% filter(u_id2=="start-stop")
ssp2 <- subset(ss_p, select = c(t_id, cadd))
ssp2$group <- "Start-Stop"

#do same for neg and then merge them
start_neg$cadd_stop <- end_neg$cadd_stop
start_neg$cadd <- (start_neg$cadd_start + start_neg$cadd_stop)/2
ss_n <- start_neg %>% filter(u_id2=="start-stop")
ssn2 <- subset(ss_n, select = c(t_id, cadd))
ssn2$group <- "Start-Stop"
start_stop <- rbind(ssp2, ssn2)


#bind into 1
#bring full five utr cadd in
fiveutr <- read.table(".../fiveutr_cadd_m1.txt")
names(fiveutr)[5] <-"t_id"
#get full cadd score for each transcript
cadd_final <- fiveutr %>% group_by(t_id) %>%summarise(cadd=mean(cadd))#18764
cadd_final$group <- "5'UTR"

#subset them all
uorf_cadd <- subset(uorf_cadd, select=-c(u_id2))

cadd_scores <- rbind(cadd_final, uorf_cadd, start_stop)
#save
#write.table(cadd_scores, ".../cadd_all_m1_17.12.22.txt")
```

\#3. RNA fold

``` r
#https://www.tbi.univie.ac.at/RNA/
#download to use as a tool in terminal
#the score its giving is: minimum free energy for the optimal secondary structure (kcal/mol) units.

##1. prepare FASTA file
#bring in 5'UTR sequences
UTR_sequences.df <- read.table(".../9.12.22 5' UTR sequences all info.txt", header = TRUE)#18764
#subset relevant cols
five_UTR_seqs.df <- data.frame(transcript = UTR_sequences.df$transcript, gene = UTR_sequences.df$gene, region = UTR_sequences.df$type, sequence = UTR_sequences.df$seq, ensg_version = UTR_sequences.df$ensgid_version, ensg =UTR_sequences.df$ensgid)

seq <- five_UTR_seqs.df$sequence
gene <- five_UTR_seqs.df$gene

write.fasta(as.list(seq), gene, file.out = "m1_utrseqsFASTA.fasta", open = "w", nbchar = 60, as.string = FALSE)

#better to make this with transcript and sequence for ease of use later

###2. run in terminal 
rnafold /Users/nwieder/m1_utrseqsFASTA.fasta > min_energy_m1.txt
#generates images too in the file (the code to not generate in first place is defunct) but just delete them
#takes ~45 mins to run

###3. Bring back to R to analyse
energy <- phylotools::read.fasta(".../min_energy_m1.txt")

#split by "(-"
library(splitstackshape)

energy2 <- cSplit(energy, "seq.text", "(-")
#the na's are the ones that are 0 i think bec they arent (-. 
#turn them into 0 and deal with the others

energy3 <- cSplit(energy2, "seq.text_2", ")")

#convert na to 0
energy3[is.na(energy3)] <- 0
#remember that they need to have - added
energy3$sep <- "-"
energy3$energy <- paste(energy3$sep, energy3$seq.text_2_1, sep="")

#now i have -0 but i need to replace that
energy3[energy3 == "-0"] <- 0

#subset and save
energy_score <- subset(energy3, select= c(seq.name, energy)) #18764
names(energy_score)[1]<-"gene"

#get score per seq length?
five <- subset(five_UTR_seqs.df, select=c(gene, sequence, transcript))

energyscore <- merge(energy_score, five, by="gene") #18766
energyscore$utr_len <- str_length(energyscore$sequence)

#remove dup transcript

energyscore2 <- energyscore[!duplicated(energyscore)]

#cehck each one has a score
na <- subset(energyscore2, is.na(energy))
#they all do


#save
#write.table(energyscore2,"freefold energyscore m1 13.12.22.txt")
```

\#4. CAGE peak data

``` r
#https://fantom.gsc.riken.jp/5/data/
#CAGE peak based annotation table of robust CAGE peaks for human samples
#CAGE_peaks/hg19.cage_peak_phase1and2combined_ann.txt

#Peaks connected to HGNC gene id's
#count the number of peaks per HGNC ID 
data <- read.table(".../hg19.cage_peak_phase1and2combined_ann.txt",header=TRUE,sep="\t")

data_ann1 <- data[!is.na(data$hgnc_id),]
length(unique(data_ann1$hgnc_id)) # 19,125 unique HGNC IDs

data_ann <- data_ann1 %>%
    mutate(count=1) %>%
    group_by(hgnc_id) %>%
    summarise(count=sum(count))

nrow(data_ann[data_ann$count<2,]) # 4,159 (21.7%)
nrow(data_ann[data_ann$count>2,]) # 11,504 (60.1%)


#some have 2 hgncs - the genes nearest a peak. We are going to use cage peaks uniquely associated to a gene, so remove the ones with >1 HGNC-id
#how many have more than 1 cage peak
data_ann$sym <- str_count(data_ann$hgnc_id, pattern=",")
sum(data_ann$sym)
nrow(data_ann[data_ann$sym>0,]) 
nrow(data_ann[data_ann$sym>1,])
#subset to only 1 HGNC_id

#sort out data_ann to only have one HGNC in a col
#delete first row
cage2 <- data_ann %>% filter(!hgnc_id=="")#19124

#remove where sym>0 - this is >1 HGNC_id
cage <- cage2 %>% filter(sym<1) #18751
#get rid of hgnc before the id
cage$hgnc_id <- sub(".*HGNC:", "", cage$hgnc_id)


#bring in MANE summary file and merge to get transcript/gene IDs
mane_summary <- read.delim(".../MANE.GRCh38.v1.0.summary.txt.gz")
#remove clinical transcripts
mane_selec <- mane_summary %>% filter(MANE_status=="MANE Select")

#remove "HGNC:" from HGNC column
manesplit <- cSplit(mane_selec, "HGNC_ID", ":")

#subset
mane2 <- data.frame("gene_id" = manesplit$Ensembl_Gene, "transcript_id" = manesplit$Ensembl_nuc, "HGNC" = manesplit$HGNC_ID_2, "gene"=manesplit$symbol)

#merge cage with mane
names(mane2)[3]<-"hgnc_id"
mane2$hgnc_id <- as.numeric(mane2$hgnc_id)
cage$hgnc_id <- as.numeric(cage$hgnc_id)
cage_gene <- merge(cage, mane2, by="hgnc_id")#16982


#save
#write.table(cage_gene, ".../cage m1 13.12.22.txt")
```

\#5. Ribo-seq uORFs

``` r
#from Chothani SP et al, A high-resolution map of human RNA translation. Mol Cell. 2022 Aug 4;82(15):2885-2899.e8. doi: 10.1016/j.molcel.2022.06.023. Epub 2022 Jul 15. PMID: 35841888.

#2 datasets. one has positions of smORF (split by introns) and tagged with unique orf_id ("smorf1"). the other has more information for each orf_id such as gene name, ORF length etc

#smorf1 available in paper "1-s2.0-S1097276522006062-mmc3.xls"
#smorf2 availble @ https://smorfs.ddnetbio.com/

smorf1 <- read.delim(".../all_final_orfCDS.txt", header = FALSE, sep="\t")
smorf2 <- read.delim(".../final_orfs_filt_v5.txt")

####contents of analysis
#1. overlap smorf and mane
#2. smorfs across leouf deciles - get smorfs per genes
#3. smorf uorf start codons
#4. codon optimality of smorfs (across leouf)
#5. mane and smorf merged uorfs

#1. overlap between predicted mane uorfs and smorf uorfs
#author maria fernandes
#########################################
###python, save this as .py file and run elsewhere
#!/usr/bin/python3

## Script to compare the coordinates of different sections


## MANEv1.0

## NOTE: in this version smORFs are filtered -- only smORFs where the start aligns 
## a 5'UTR region from a MANE transcript are considered! 

from faulthandler import cancel_dump_traceback_later
from sqlite3 import Row
import time
import sys
import pandas as pd
from numpy import empty, single
from regex import P
from functions import *


start_time = time.time()

print('python3 5.compare_smorfs_uorfs_location_MANEonly.py <smorfs_coords_filename> <which_smorfs> <uorfs_coords_filename> <MANE_filename> <outputname>') 
print('python3 5.compare_smorfs_uorfs_location_MANEonly.py smorfs_coord_type_2022-12-13.tsv uORF ORFs_genomic_coord_MANEv1.0_12.12.22.tsv ../0.data/MANE/1.0/MANE.GRCh38.v1.0.select_ensembl_genomic_columnNames.gff overlap_MANEsmORFs_uORFs_2022-12-19.tsv')
print('<which_smorfs>: uORF (includes overlap_uORF), dORF (includes overlap_dORF), and ncORF')
print('Note:Script computes for all type of smORFs and the selected type in particular.')
##print('for multiple smorf types: uORF-dORF-ncORF')

## There are some uORFs == smORFs

## Open the files
smorfs_coord_filename = sys.argv[1]
smorf_type = sys.argv[2]
uorfs_filename = sys.argv[3]
mane_filename = sys.argv[4]
output_filename = sys.argv[5]

## types of smORFs considered
##filter_smorf = smorf_type.split('-')
##print(filter_smorf)


## 1- read smORFs coordinates
smorfs_df = read_file(smorfs_coord_filename, '\t', 0)
smorfs_df['chr'] = smorfs_df['chr'].str.replace('chr','') ## remove chr prefix, as smorfs data does not have it
##print(smorfs_df)


## only smORFs with the specific type
filtered_smorfs_df = smorfs_df[smorfs_df['type'] == smorf_type]
##filtered_smorfs_df = smorfs_df.loc[smorfs_df['type'].str.contains(smorf_type, case=False)] ## old line to get uORFs and uORFs_overlap (both)
##print(filtered_smorfs_df)
##print(filtered_smorfs_df.type.unique()) ## to confirm there is no uORF_overlap
print('riboseq uORFs: ', filtered_smorfs_df.shape[0])

## 1- check start canonical vs non-canonical and keep just canonical for downstream
## only cannonical starts 
canonical_filtered_smorfs_df = filtered_smorfs_df[filtered_smorfs_df['start_codon'] == 'ATG']
##print(canonical_filtered_smorfs_df)
print('riboseq uORFs non-canonical: ', filtered_smorfs_df.shape[0]- canonical_filtered_smorfs_df.shape[0])
print('riboseq uORFs cannonical start: ', canonical_filtered_smorfs_df.shape[0])


## NOTE: NEW part
## filter smORFs where start is within a 5'UTR region
# 1- read mane file and get 5'UTR regions
fivePrimeMANE_df = read_file(mane_filename, '\t', 0)
fivePrimeMANE_df['chr'] = fivePrimeMANE_df['chr'].str.replace('chr','') ## remove chr prefix, as smorfs data does not have it
fivePrimeMANE_df = fivePrimeMANE_df[fivePrimeMANE_df['type'] == 'five_prime_UTR']
##print(fivePrimeMANE_df)
##print(fivePrimeMANE_df.columns)


count_not5primeMANE = 0
to_remove = []
for index, row in canonical_filtered_smorfs_df.iterrows():
    ## any 5'UTR where smorf start and end fall within
    fivePrimeMANE_df_small = fivePrimeMANE_df[(fivePrimeMANE_df['start'] <= row.start) & (fivePrimeMANE_df['end'] >= row.start)& (fivePrimeMANE_df['start'] <= row.end) & (fivePrimeMANE_df['end'] >= row.end) & (fivePrimeMANE_df['chr'] == row.chr) & (fivePrimeMANE_df['strand'] == row.strand)]
    if fivePrimeMANE_df_small.empty:  ## if there is no 5'UTR start and end fall in -- remove it! 
        ##print('empty')
        to_remove.append(int(index))
        count_not5primeMANE += 1 

canonical_filtered_smorfs_df.drop(to_remove, axis=0, inplace=True)

print('smORFs type with NO start within 5\'UTR MANE - No MANE:', count_not5primeMANE)
print('riboseq uORFs canonical MANE: ', canonical_filtered_smorfs_df.shape[0])


## 2- Read uORFs coordinates
uorfs_df = read_file(uorfs_filename, '\t', 0)
## initially 19131
## remove start-stop
uorfs_df = uorfs_df[uorfs_df['u_id2'] == smorf_type]
print('predicted uORFs', uorfs_df.shape[0])
##print(uorfs_df.u_id2.unique()) ## make sure there is only uORFs

## 3 - Create output 
out = open(output_filename, 'w')
out.write('smORF_id\tchrm\tstrand\tsmORF_start\tsmORF_end\tuORF_ID\tuORF_start\tuORF_end\toverlap_type\n' )

## NOTE: WE skip the all_smORFS vs predicted uORFS and center only on the 5'UTR smORFs

## 4 - Check overlap
# for each 5'UTR smorf, check in the uORFs list

## ONLY canonical and MANE

overlap_subset_atg = 0
smorf_within_uorf_subset_atg = 0
start_overlap_subset_atg = 0
end_overlap_subset_atg = 0
smorf_larger_subset_atg = 0
same_smorf_uorf_subset_atg = 0

no_overlap_smorfs_subset_atg = []

for index, row in canonical_filtered_smorfs_df.iterrows(): ##  row = smorf, as there is a smorf per line in the dataframeß
    ##print(row)
    search_id = row['##smORF_ID']
    search_chrm = row['chr']
    search_start = row['start']
    search_end = row['end']
    search_strand = row['strand']
    search_type = row['type']
    search_start_codon = row['start_codon']
    
    ##print(search_id, search_chrm, search_start, search_end, search_strand)
    
    ## uORFs_end_postitions for the chromosome under study
    same_chrm = uorfs_df.loc[uorfs_df['chromosome'] == search_chrm]
    search_uorfs = same_chrm.loc[same_chrm['strand_mane'] == search_strand]
    ## filter smORFs to uORFs -- TODO: Change this for including start-stop
    search_uorfs = search_uorfs.loc[same_chrm['u_id2'] == search_type]

    ## check if smORF == uORF
    equal = search_uorfs.loc[(search_uorfs['g_start_coord_ref'] == search_start) & (search_uorfs['g_end_coord_ref'] == search_end)]
    smorf_bigger =  search_uorfs.loc[(search_uorfs['g_start_coord_ref'] > search_start) & (search_uorfs['g_end_coord_ref'] < search_end)]

    if search_strand == '+':
        ## smorf start between start and end of uorf and end of smorf larger than uorf end
        overlap_end_uorf = search_uorfs.loc[(search_uorfs['g_start_coord_ref'] < search_start) & (search_uorfs['g_end_coord_ref'] > search_start) & (search_uorfs['g_end_coord_ref'] < search_end)]
        overlap_start_uorf = search_uorfs.loc[(search_uorfs['g_start_coord_ref'] > search_start) & (search_uorfs['g_end_coord_ref'] > search_end) & (search_uorfs['g_start_coord_ref'] < search_end)]
        inside =  search_uorfs.loc[(search_uorfs['g_start_coord_ref'] < search_start) & (search_uorfs['g_end_coord_ref'] >= search_end)]

    elif search_strand == '-':
        ## start of the smorf = end coordinate between start and end of uORF and start before uORF start
        overlap_end_uorf = search_uorfs.loc[(search_uorfs['g_start_coord_ref'] > search_start) & (search_uorfs['g_end_coord_ref'] > search_end) & (search_uorfs['g_start_coord_ref'] < search_end)]
        overlap_start_uorf = search_uorfs.loc[(search_uorfs['g_start_coord_ref'] < search_start) & (search_uorfs['g_end_coord_ref'] > search_start) & (search_uorfs['g_end_coord_ref'] < search_end)]
        inside =  search_uorfs.loc[(search_uorfs['g_start_coord_ref'] <= search_start) & (search_uorfs['g_end_coord_ref'] > search_end)]

    if not equal.empty:  ## smorf 3
        ##print('smorf == uorf')
        ##print(equal)
        same_smorf_uorf_subset_atg += 1
        overlap_subset_atg += 1 
        status_subset_atg = 'equal'

        ##sys.exit()
    elif not inside.empty: ## smorf 4
        ##print(inside)
        smorf_within_uorf_subset_atg += 1
        overlap_subset_atg += 1 
        status_subset_atg = 'within_uORF'

    elif not smorf_bigger.empty: ## smorf 5
        ##print(smorf_bigger)
        smorf_larger_subset_atg += 1
        overlap_subset_atg += 1
        status_subset_atg = 'larger_than_uORF'
    
    ## check if they overlap partially
    elif not overlap_end_uorf.empty: ## smorf 1
        end_overlap_subset_atg += 1 
        overlap_subset_atg += 1
        status_subset_atg = 'overlap_partially'

    elif not overlap_start_uorf.empty: ## smorf 2
        start_overlap_subset_atg += 1 
        overlap_subset_atg += 1
        status_subset_atg = 'overlap_partially'
    
    ## no overlap
    else: ## smorf 6
        no_overlap_smorfs_subset_atg.append(search_id)
        status_subset_atg = 'no_overlap'
    
    
    out.write(search_id + '\t' + search_chrm + '\t' + search_strand + '\t' + search_id + '\t' +  str(search_start) + '\t' +  str(search_end) + '\t' + status_subset_atg + '\n' )

out.close()


print('')
print('')
print('MANE only Analysis')
print('')
print('')
print('Total riboSeq', smorf_type, ' with ATG (canonical only) start:', canonical_filtered_smorfs_df.shape[0])
print('Total riboSeq', smorf_type, ' overlapping at least 1 pred_uORF: ', overlap_subset_atg)
print('Total riboSeq', smorf_type, ' no overlap: ', len(no_overlap_smorfs_subset_atg))
print('--')
print('riboSeq', smorf_type, ' = pred_uORF: ', same_smorf_uorf_subset_atg)
print('riboSeq', smorf_type, ' fully within pred_uORF: ', smorf_within_uorf_subset_atg)
print('riboSeq', smorf_type, ' overlap pred_uORF end: ', end_overlap_subset_atg)
print('riboSeq', smorf_type, ' overlap pred_uORF start: ', start_overlap_subset_atg)
print('riboSeq', smorf_type, ' larger than pred_uORF: ', smorf_larger_subset_atg)


print('')
print('done')


end = (time.time() - start_time)/ 60.0

print(end, ' minutes.')
#########################

#plot in R
all_riboseq_uorfs <- 5052
rboseq_uorfs_canonical <- 2764
riboseq_uorfs_non_canonical <- 2288
riboseq_uorfs_canonical_noMANE <- 1325
riboseq_uorfs_canonical_MANE <- 1439
equal <- 1430
overlap_end <- 1
smorf_larger <- 5

count <- c(riboseq_uorfs_canonical_noMANE, riboseq_uorfs_non_canonical, 
           smorf_larger, equal, overlap_end)

labels_name <- c("Non-MANE", "Non-canonical", "riboseq longer", "exact overlap", "overlap end")
labels <- paste(labels_name, round(100* (count/all_riboseq_uorfs), 2), "%")


colors <- c("grey", "grey", "violet", "blue", "yellow")

pie(count, labels = labels, col= colors)
#####

# results from groupings put into excel to generate automatic pie chart for ease by Nechama #


#2. for smorfs across leouf deciles - get smorfs per genes

#i wnt smorfs per gene (uORFs, all not just canonical)
uorf <- smorf2 %>% filter(iORF_type == "uORF")


#aggregate to get smorf per gene
uorf$one <- 1
smorf_gene <- aggregate(uorf$one, by = list(gene_id = uorf$gene_id), FUN=sum)
names(smorf_gene)[2]<-"number_uORF"

#save
#write.table(smorf_gene, ".../smorf_gene.txt")



#3. smorf uORF start codons
uorf <- smorf2 %>% filter(iORF_type == "uORF") 
#write.table(uORFs, ".../ribo_seq_uo.txt")

starts <- data.frame(table(uorf$starts))
starts$total <- sum(starts$Freq)
starts$perc <- starts$Freq/starts$total *100

#plot to see proportions of uORF start codons in this ribo-seq set
ggplot(starts, aes(reorder(Var1, perc),perc))+geom_bar(stat = "identity",fill="navy") +
  coord_flip() + theme_bw() + ggtitle("Start Codon Proportions in smORF uORFs")+ylab("Percentage")+xlab("Start Codon")

#54.711006 start at ATG
#100-54.711006 == 45.3 non-atg start



#4. Codon optimality for smORFs
# need to get the smORF uORF codons using their locations - remember they are split by introns.so if a ribo-seq uorf has an intron in it, it is given 2 entries with same iorf_id.
# part 1: get smorf uorf codons (pos and neg seperately). this is through a loop to stitch the uorfs which are seperated by introns
# part 2: convert smorf uorf codons into codon values acc to codon optimality.

#use Forrest HeLa cell line and they have classed as optimal and non optimal
#https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7018022/
#pone.0228730.s009.xlsx
#open in excel, and save as a text file

forrest <- read.table(".../hela forrest codonoptimal.txt",header=TRUE)
#turn opt and non-opt into numeric vals
hela <- forrest %>% mutate(id2 = ifelse(HeLa_IsOpt == "NonOpt","0",ifelse(HeLa_IsOpt =="Opt", "1", 0)))


#1. set up df 
#merge uorfs details with smorf1 to get positions
names(smorf1)[9]<-"iORF_id" 
ribo_seq <- merge(uorf, smorf1, by="iORF_id")
#this wil have dup ids bec there are uorfs split by introns

#2. split into + and - 
#first fix chr col
ribo_seq$chr <- paste0("chr", ribo_seq$V1)
#change the sex chromosomes
ribo_seq["chr"][ribo_seq["chr"]=="chr24"] <- "chrX"
ribo_seq["chr"][ribo_seq["chr"]=="chr25"] <- "chrY"

ribo_pos <- ribo_seq %>% filter(strand=="+")
ribo_neg <- ribo_seq %>% filter(strand=="-")

#3. POS: get uorf seqs from positions
library("BSgenome.Hsapiens.UCSC.hg38")
human <- getBSgenome("BSgenome.Hsapiens.UCSC.hg38")

ribo_pos$seq <- as.character(Biostrings::getSeq(BSgenome.Hsapiens.UCSC.hg38, ribo_pos$chr, ribo_pos$V4, ribo_pos$V5))


#4. stitch the uORFs split by introns
#pull out all unique iORF_ids
u <- as.data.frame(unique(ribo_pos$iORF_id))
u$seq <- ""

for (i in 1:nrow(u)){
  my_id<-u[i,1]
dd<- subset(ribo_pos, iORF_id==my_id)
tt <-dd[order(dd$V4),]
char <- character()
 for (j in 1:nrow(tt)){
    cod <- tt$seq[j]
    #print(cod)
    char[j]<-cod
}
  u$seq[i] <- paste(char, collapse = "")
  }

#stitches them according to uORF start position

#remove the first codon
u$seq2<- str_sub(u$seq, start = 4, end = -1L)


#5. get the codon value (codon optimality)
#hela
n <- 3

#remove stop codons can do it in seq row
#not sure if to remove start too?
#not working but maybe the uORFs are not divisible by 3 so check
u$uorf_len <- str_length(u$seq2)
u$three <- u$uorf_len/3

for (q in 1:nrow(u)){
  seq<- substr(u$seq2[q], 1, u$uorf_len[q]-3)  #remove stops
  #print(seq)
  what  <- substring(seq, seq(1,nchar(seq),n), seq(n,nchar(seq), n))
  rv <- integer()
  for (e in 1:length(what)){
    cod <- hela$id2[hela$Codon==what[e]]
    #print(cod)
    rv[e]<-cod
}
  u$split[q] <- paste(rv, collapse = "_")
}

#merge u with ribo_pos
names(u)[1]<-"iORF_id"
ribo_pos2 <- merge(u, ribo_pos, by="iORF_id")

#5. translate string of numbers into codon optimality score for each now
ribo_pos2$optimal <- sapply(strsplit(ribo_pos2$split, "_"), function(x) sum(as.integer(x)))

#i want a optimality score per uorf length. the codons looked at for optimality include start so do three - 1 .
ribo_pos2$codon_no <- ribo_pos2$three-1
ribo_pos2$score <- ribo_pos2$optimal/ribo_pos2$codon_no


####REVERSE
#3. get uorf seqs for NEG
ribo_neg$seq <- as.character(Biostrings::getSeq(BSgenome.Hsapiens.UCSC.hg38, ribo_neg$chr, ribo_neg$V4, ribo_neg$V5))
#this will pull the sequence i will rev comp later
#3.1 reverse complement sequences
library(seqinr)
#cant do a whole column, need to select line by line
for(i in 1:length(ribo_neg$seq)){
  ribo_neg$seq2[i]<-c2s(rev(comp(s2c(ribo_neg$seq[i]))))
}

#4. stitch the uORFs split by introns
uni <- as.data.frame(unique(ribo_neg$iORF_id))
uni$seq <- ""

for (p in 1:nrow(uni)){
  my_id<-uni[p,1]
dd<- subset(ribo_neg, iORF_id==my_id)
tt <-dd[order(dd$V4, decreasing = TRUE), ]#i need to order biggest to smallest
char <- character()
 for (l in 1:nrow(tt)){
    cod <- tt$seq2[l]
    #print(cod)
    char[l]<-cod
}
  uni$seq[p] <- paste(char, collapse = "")
  }

#remove start codons
uni$seq2<- str_sub(uni$seq, start = 4, end = -1L)
#5. get the codon value (codon optimality)
#remove stop codons can do it in seq row

uni$uorf_len <- str_length(uni$seq2)
uni$three <- uni$uorf_len/3
#convert to upper case(reqiured)
uni$seq2 <- toupper(uni$seq2)

for (q in 1:nrow(uni)){
  seq<- substr(uni$seq2[q], 1, uni$uorf_len[q]-3)  #remove stops
  #print(seq)
  what  <- substring(seq, seq(1,nchar(seq),n), seq(n,nchar(seq), n))
  rv <- integer()
  for (e in 1:length(what)){
   cod <- hela$id2[hela$Codon==what[e]]
     #print(cod)
    rv[e]<-cod
}
  uni$split[q] <- paste(rv, collapse = "_")
}

#6. merge with ribo_neg
names(uni)[1]<-"iORF_id"
ribo_neg2 <- merge(uni, ribo_neg, by="iORF_id")
#get codon optimality score for each now
ribo_neg2$optimal <- sapply(strsplit(ribo_neg2$split, "_"), function(x) sum(as.integer(x)))
#i want a optimality score per uorf length. .
ribo_neg2$codon_no <- ribo_neg2$three-1
ribo_neg2$score <- ribo_neg2$optimal/ribo_neg2$codon_no


#7. Sort df's merge and remove dups. Then can merge with LOEUFs and plot optimality across deciles woowoo
ribo_pos3 <- subset(ribo_pos2, select=c(iORF_id,ORF_id,gene_name, gene_biotype, gene_id, len, strand, starts, V4, V5, chr, uORF_seq=seq.y,optimal,score))
names(ribo_pos3)[12]<- "uORF_seq"
#contains dups remove later
#subset neg
ribo_neg3 <- subset(ribo_neg2, select=c(iORF_id,ORF_id,gene_name, gene_biotype, gene_id, len, strand, starts, V4, V5, chr, seq2.x,optimal,score))
names(ribo_neg3)[12]<- "uORF_seq"


#bind df and remove dups
ribo_opt <- base::rbind(ribo_pos3, ribo_neg3)#5574

#remove dups iORF_id
u <- unique(ribo_opt$iORF_id)#5052 unique uORFs
#remove based on position bec im lazy and cant remember how to remove dups
ribo_opt2 <- ribo_opt[!duplicated(ribo_opt$iORF_id), ]

#save external
#write.table(ribo_opt2,".../smorf uorf codon optimality.txt")


##5. 5'utrs with smorf in
#how many genes have a smorf in? and whats the range of smorf uorfs per gene?
#merge smorf2 with mane5utrs by gene name

sm_utr <- merge(length_exon, smorf2, by="gene_name")
#group by gene name
smutr <- sm_utr %>% group_by(gene_name) %>% summarise(n())
#3918 genes have smorf uorfs 
nrow(smutr)/nrow(length_exon)
# 0.2088041 = 20.9%
#range 1-11
```

\#6. Translational Efficiency (Noderer Et al 2014)

``` r
# Norderer 2014 TE data - Noderer WL, Flockhart RJ, Bhaduri A, Diaz de Arce AJ, Zhang J, Khavari PA, et al. Quantitative analysis of mammalian translation initiation sites by FACS-seq. Mol Syst Biol. 2014 Aug 28;10(8):748
#"Supplementary Table S2. TIS efficiency reference table. TIS efficiency values for all 65,536 possible AUG containing TIS sequence. Values were obtained with the dinucleotide PWM. 95% confidence intervals are provided."
#downloaded and manually opened the txt file and deleted the first line
#only AUG starts
#The higher the score the stronger the TE is

TE_norderer <- read.delim(".../norderer TE 6.4.22.txt", sep = '\t', header = TRUE)

#bring in my uATG data and get this sequence range for each and then can merge them to get the new "kozak" strength for them. 
#for AUGs that are too close to the TSS exclude, because the ribosome wouldnt read them. for the ones that are too close to CDS, extract and deal with separately

oorf <- read.table(".../oorf_12.12.22.txt") #3416
uo<- read.table(".../uo_ss_12.12.22.txt")#19131 uorf and start-stops

#make one df that just has what we need
oorf$orf_type <- "oorf"
oo <- subset(oorf, select = c(transcript, gene,sequence, atg_pos,orf_type))
uo <- subset(uo, select=-c(stop_pos))

orf <- rbind(oo, uo)#22547

#dealing with ATGs too close to TSS or CDS
#1. if atg is too close to TSS then get rid. TE UUCAUCAUGCA length .. AUG needs to be min pos 7 from TSS so .. 
ORFs2 <- orf %>% filter(atg_pos>6) #21881
#666 ATGs TE overlapping TSS
#put them in their own df
tss <- orf %>% filter(atg_pos<7)#577..
#are they oORF or uORF
table(tss$orf_type)
#oORF uORF start-stop
#187  445   34



#2. if too close to CDS keep somewhere else to deal with later
#get UTR length
ORFs2$UTR_len <- str_count(ORFs2$sequence)
# needs to have 2 nucelotides from CDS, so UTR length - atg stop pos == 
ORFs2$atgstop <- ORFs2$atg_pos+2
ORFs2$cdsdis <- ORFs2$UTR_len- ORFs2$atgstop
#filter out less than 2
cds_close <- ORFs2%>%filter(cdsdis<2)#51 where TE overlaps with CDS

#i want end of UTR position. then i can get my code to pull out UTR end plus 2 bases ..
##up to here
#MANE.GRCh38.v0.92.select_ensembl_genomic.gff
five_utrs <- read.table(".../mane_five.txt")
names(five_utrs)[15]<-"chr"

#aggregate to keep last stop position for an exon
#get 5' UTR end positions
five_pos <- five_utrs %>%filter(V7 == "+")
five_neg<- five_utrs %>%filter(V7 == "-")

#positive:
five_pos2 <- five_pos %>% group_by(gene_name) %>% slice(which.max(V5))
names(five_pos2)[19]<- "utr_end"

#subset
five_pos_start <-subset(five_pos2, select = c(chr, V4, utr_end, V7, gene_name, transcript_id)) 

#negative
#want for each gene the smallest utr end as this is closest to the cds 
five_neg2 <- five_neg %>% group_by(gene_name) %>% slice(which.min(V5))
names(five_neg2)[18]<- "utr_end"
five_neg_start <- subset(five_neg2, select = c(chr, utr_end,V5, V7, gene_name, transcript_id)) 

#name them correctly then merge
names(five_pos_start)[4]<- "strand"
names(five_neg_start)[4]<- "strand"
names(five_pos_start)[2]<-"ignore"
names(five_neg_start)[3]<-"ignore"

#bind
utr_pos <- rbind(five_pos_start, five_neg_start)

#now merge with cdsclose
nameS(cds_close)[1]<-"transcript_id"
cds_close2 <- merge(utr_pos, cds_close, by="transcript_id")

#get the code to pull the plus 2 positions from CDS
library(BSgenome)
library(BiocManager)
human <- getBSgenome("BSgenome.Hsapiens.UCSC.hg38")
library("BSgenome.Hsapiens.UCSC.hg38")

cds_close2$cds <- as.character(Biostrings::getSeq(BSgenome.Hsapiens.UCSC.hg38, cds_close2$chr, cds_close2$utr_end, cds_close2$utr_end+1))

#paste them onto sequence and then do my code to pull out TE?
cds_close2$seq2 <- paste0(cds_close2$sequence, cds_close2$cds)

#3. get the TE for all
#remove the ones that were too close to cds as i deal with them separately
#change this to a new df name! 
ORFs2 <- ORFs2%>%filter(!cdsdis<2)
#get TE
ORFs2$TE_range <- str_sub(ORFs2$sequence, start = ORFs2$atg_pos -6, end = ORFs2$atg_pos+4)
#now i need to replace all T>U
ORFs2$TE_range2 <- str_replace_all(ORFs2$TE_range, "T", "U")

#get TE for ones that are too close to CDS that i just got their nucleotides
cds_close2$TE_range <- str_sub(cds_close2$seq2, start = cds_close2$atg_pos -6, end = cds_close2$atg_pos +4)
cds_close2$TE_range2 <- str_replace_all(cds_close2$TE_range, "T", "U")

#merge orfs2 and cdsclose 
cds2 <- subset(cds_close2, select=-c(chr,ignore, utr_end,strand,gene_name,cds, seq2))
names(ORFs2)[1]<-"transcript_id"
orfs_te <-rbind(cds2,ORFs2)

#now merge to get TE in the ORF df
names(TE_norderer)[1]<- "TE_range2"
ORF_te2 <- merge(TE_norderer, orfs_te, by = "TE_range2")#21881

#now i  have TE for all my uORFs and oORFs and start-stops. the reason why orfs_te is less than all the ORFs i brought in originally is bec ~600 ATg were too close to the TSS.. 

#save TE per uAUG 
#the higher the efficiency the more likely initiation 
#write.table(ORF_te2, ".../orf_TE_noderer_m1.txt")
```
